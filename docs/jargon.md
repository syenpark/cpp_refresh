# Real time engineering Jargon I must know

- `Hot path / hot loop`

    The code that runs all the time, for every event.

    ```cpp
    read_inference_metadata(msg) {
        update_objects_info(msg);
        send_results_to_kafka();
    }
    ```

    That function is hot like receiving object detection metadata in real time for 25 FPS.

- `Cold path`

    Code that runs rarely like startup, confing loading, logging, metrics export.

- `Latency` vs `Throughput`

    How long des one thing take? vs How many things per second?

    `Tail latency`: The slowest cases, not the average.

- `Jitter`

    Random variation in latency, which mostly from OS scheduling, memory allocation, cache misses, NUMA

- `Cache miss`

    CPU wanted data, it wasn't in cache, which could result in CPU stalls and waits on RAM.

    ```shell
        CPU Core
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Registers                  â”‚  â† fastest
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            L1 Cache
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ L1 Cache (per core)        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚   âŒ miss
            L2 Cache
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ L2 Cache                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚   âŒ miss
            L3 Cache
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ L3 Cache (shared)          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚   âŒ miss
            â”‚
            RAM (NUMA local?)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ RAM                        â”‚  â† sloooow
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    ```

- `False sharing`

    Two cores write different variable on the same cache line, which could lead to cache ping-pong and massive latency spikes.

    ```shell
        Cache Line (64 bytes)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ var_A (Core 0) â”‚ var_B (Core 1) â”‚ padding  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    ```

    This is harmful, as the below operations repeat.

    ```shell
    Core 0                         Core 1
    ------                         ------
    write var_A
    â”‚
    â–¼
    cache line owned by Core 0

                                write var_B
                                    â”‚
                                    â–¼
    cache line invalidated on Core 0
                                    â”‚
                                    â–¼
    cache line owned by Core 1

    write var_A again
    â”‚
    â–¼
    cache line invalidated on Core 1

    Time â†’
    Core 0: [write][WAIT][write][WAIT][write]
    Core 1: [WAIT][write][WAIT][write][WAIT]
    ```

    How to avoid this;

    ```cpp
    struct alignas(64) OrderBook {
        int price;
        int qty;
    };
    ```

    or explicit padding:

    ```shell
    | var_A | padding (64 bytes) | var_B |
    ```

- `Page fault`

    Memory page not mapped yet, so OS intervention with microseconds to millliseconds delay could occur.

- `Memory locality`

    Data is physically close to the CPU that uses it. Speed levels are register > L1 > L2 > L3 > RAM (local) > RAM (remote NUMA).

- `NUMA`

    Some RAM is farther from your core, so your core accesses RAM that belongs to another CPU socket.

    ```shell
    # NUMA system

    Socket 0                         Socket 1
    â”€â”€â”€â”€â”€â”€â”€â”€                         â”€â”€â”€â”€â”€â”€â”€â”€
    Core 0â€“15                        Core 16â€“31
    Local RAM 0                      Local RAM 1

    # NUMA miss
    Core 2 (Socket 0)
        â”‚
        â–¼
    L1 âŒ
    L2 âŒ
    L3 âŒ
        â”‚
        â–¼
    RAM 0 âŒ
        â”‚
        â–¼
    RAM 1 (remote) ğŸ’€

    # NUMA miss Timeline view
    Time â†’
    [ execute ][ WAIT WAIT WAIT ][ resume ]
    ```

    `NUMA miss` is walking to another building (remote memory hop) vs `False sharing` is fighting over the same desk (cache line bouncing).

    |Aspect|False sharing|NUMA Miss|
    |------|---|---|
    |RAM accessed|X|O|
    |cause|Cache line sharing|Wrong memory node|
    |Fix|Padding / alignment|Pin threads + memory|
    |Detectability|Very hard|Hard|
    |Tail latency|High (p999 spike)|High (random latency)|

- `Allocator`

    The system that decides where heap memory comes from.

    ```cpp
    malloc
    new
    tcmalloc
    jemalloc
    ```
